{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48877d19-adf2-4ea0-98a8-f0cfedb8c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models\n",
    "\n",
    "import cifar_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21567712-c083-4dc0-967c-3e07a1348da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    #f'cuda:{torch.cuda.device_count() - 1}' if torch.cuda.is_available() else 'cpu'\n",
    "    'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "capability = torch.cuda.get_device_capability() if device.type == 'cuda' else None\n",
    "torch.jit.enable_onednn_fusion(True)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_device(device)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "mem_info = torch.cuda.mem_get_info(device=device) # global (free, total) GPU memor\n",
    "print(f'Device: {device}, Type: {device.type}, Compute_Capability: {capability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f8ece-c983-47d2-95e8-4b8b62b314b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    GPU_info = {\n",
    "        'device_name': torch.cuda.get_device_name(device=device),\n",
    "        'mem_info': torch.cuda.mem_get_info(device=device),\n",
    "    }\n",
    "    print(f'GPU Name: {GPU_info['device_name']}, Memory (free, total): {GPU_info['mem_info']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2a048-8f0e-49f0-b996-c81d6efdfa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/.pytorch/dataset'\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transform_pre = nn.Sequential(\n",
    "    transforms.ToDtype(torch.uint8, scale=True),\n",
    "    )\n",
    "transform_post = nn.Sequential(\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(dtype=torch.float32, scale=True),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    ")\n",
    "transform = {\n",
    "    'train': nn.Sequential(\n",
    "        transform_pre,\n",
    "        transforms.RandomResizedCrop(size=32, scale=(.8, 1), ratio=(.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transform_post,\n",
    "    ),\n",
    "    'eval': nn.Sequential(\n",
    "        transform_pre,\n",
    "        #transforms.Resize(size=256),\n",
    "        #transforms.CenterCrop(size=size),\n",
    "        transform_post,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf58bb6-5f43-4196-8003-523c7d54d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/.pytorch/datasets'\n",
    "dataset = {\n",
    "    'train': datasets.CIFAR100(root=root, train=True, transform=transform['train'], download=True),\n",
    "    'eval': datasets.CIFAR100(root=root, train=False, transform=transform['eval'], download=True),\n",
    "}\n",
    "model = cifar_resnet.CIFAR_ResNet(n=3, num_classes=100, p=0.2).to(device, memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7128146-3723-4b57-89d5-db613ce45166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(model, dataset, dataloader, criterion, optimizer):\n",
    "    # record\n",
    "    record_loss, record_acc = 0, 0\n",
    "    # train\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # load data\n",
    "        inputs = data[0].to(device, non_blocking=True, memory_format=torch.channels_last)\n",
    "        labels = data[1].to(device, non_blocking=True)\n",
    "        # compute\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        with torch.autocast(device.type, enabled=AUTOCAST_FLAG):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record\n",
    "        #record_loss += loss.item()\n",
    "        #record_acc += (labels.argmax(dim=1) == outputs.argmax(dim=1)).sum().item()\n",
    "        break\n",
    "    # results\n",
    "    #record_loss /= len(dataloader) # mean loss\n",
    "    #record_acc /= (len(dataset) - (len(dataset) % batch_size)) if AUTOCAST_FLAG else len(dataset)\n",
    "    return record_loss, record_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ce604-b07c-46ab-83c8-facb6fd6ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed_mem(fn):\n",
    "    torch.cuda.reset_peak_memory_stats(device=device)\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000, torch.cuda.max_memory_allocated(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91180b58-bb68-43ca-b8f1-a78878814d4a",
   "metadata": {},
   "source": [
    "## BS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8b892-5281-4fd8-9769-7a0201314881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=num_workers,\n",
    "        #collate_fn=collate_fn if MIX_FLAG else None,\n",
    "        #pin_memory=True,\n",
    "        #drop_last=AUTOCAST_FLAG,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=num_workers,\n",
    "        #pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83b753-3589-4e30-98ac-99709b71a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b23568-8c85-4bf7-b634-3451c7760845",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_1 = mem_cost\n",
    "print(mem_bs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b543c6e-2e61-485e-b701-607824fe1859",
   "metadata": {},
   "source": [
    "## BS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47fdb2-cbb2-4b8b-9056-fc2acb151ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=num_workers,\n",
    "        #collate_fn=collate_fn if MIX_FLAG else None,\n",
    "        #pin_memory=True,\n",
    "        #drop_last=AUTOCAST_FLAG,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=num_workers,\n",
    "        #pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3642b-c47a-470c-a40e-78bc86bedb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101e321-b445-45a3-8ce3-647980d783b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_2 = mem_cost\n",
    "print(mem_bs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6b230-1cac-43d9-b0b8-4f8f74a5f284",
   "metadata": {},
   "source": [
    "## Predict ${BS}_{MAX}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89883370-3ac1-41ef-8696-8699d514f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_cost_gap = mem_bs_2 - mem_bs_1\n",
    "print(mem_cost_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1491a10-15ed-49d3-9912-af53ff0c3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_max = (GPU_info['mem_info'][0] - mem_bs_1) // mem_cost_gap + 1\n",
    "print(batch_size_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8015a23-ba04-4664-9bce-1aaa8a106adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_max_predict = mem_bs_1 + (batch_size_max - 1) * mem_cost_gap\n",
    "print(mem_bs_max_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb32abd-76ff-4456-a4e3-843dbf930205",
   "metadata": {},
   "source": [
    "## BS = MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94515f92-0bfb-48b1-ae25-d4e33695cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = batch_size_max\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=num_workers,\n",
    "        #collate_fn=collate_fn if MIX_FLAG else None,\n",
    "        #pin_memory=True,\n",
    "        #drop_last=AUTOCAST_FLAG,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=num_workers,\n",
    "        #pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ff518-2c83-4b82-938a-34dbc0876f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47567e-2ec5-49d7-9b6a-eb544c92550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_size_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b98cf4-6149-432e-bbb0-08c0c8da55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_max_measure = mem_cost\n",
    "print(mem_bs_max_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dfd6b-81d7-47e0-8a94-5df274c38715",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GAP: {(GPU_info['mem_info'][0] - mem_bs_max_measure) / 2**20} MiB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d13f90-89a6-4f15-a72a-b4c6b3e101c1",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9a008-b17f-4b6f-b5eb-61c9694777c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GPU Name: {GPU_info['device_name']}, Memory (free, total): {GPU_info['mem_info']}')\n",
    "print(f'Predict batch size: {batch_size_max}')\n",
    "print(f'Predict memory usage: {mem_bs_max_predict} Byte == {mem_bs_max_predict // 2**20: g} MiB')\n",
    "print(f'Measure memory usage: {mem_bs_max_measure} Byte == {mem_bs_max_measure // 2**20: g} MiB')\n",
    "print(f'Gap of memory usage: {mem_bs_max_predict - mem_bs_max_measure} Byte == {(mem_bs_max_predict - mem_bs_max_measure) // 2**20: g} MiB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad3390-6402-4878-bf8a-9d47a52a1e77",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2b542-6077-42b2-bf48-2d27a24425d4",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0ca46-4917-4dcd-a995-61a5a3c9858a",
   "metadata": {},
   "source": [
    "SAVE = True\n",
    "DPI = 300 if SAVE else 72 # [72, 150, 240, 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae765d4b-d6fa-40a1-9b1b-f5a5a0cd95ba",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "mem_label = ['predict', 'measure']\n",
    "mem_usage = [mem_bs_max_predict / 2**20, mem_bs_max_measure / 2**20]\n",
    "bar_labels = ['red', 'blue']\n",
    "bar_colors = ['tab:red', 'tab:blue']\n",
    "\n",
    "ax.bar(mem_label, mem_usage, label=mem_label, color=bar_colors)\n",
    "ax.axhline(y=GPU_info['mem_info'][1] / 2**20, color=\"black\", linestyle=\"--\")\n",
    "#ax.axhline(y=mem_bs_max_predict, color=\"red\", linestyle=\"--\")\n",
    "ax.axhline(y=mem_bs_max_measure / 2**20, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "ax.set_ylabel('memory usage (MiB)')\n",
    "ax.set_title('(ResNet18, CIFAR-100) Memory Usage')\n",
    "#ax.legend(title='Fruit color')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde28360-5e98-49fc-b0fb-73b8b24c771f",
   "metadata": {},
   "source": [
    "x = [1]\n",
    "x2 = [0.8]\n",
    "h = [mem_bs_max_predict / 2**20]\n",
    "h2 = [mem_bs_max_measure / 2**20]\n",
    "plt.bar(x, h, color='tab:blue', width=0.4, align='edge')\n",
    "plt.bar(x2, h2, color='tab:red', width=0.4)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e7c4a-51bc-4b98-b04c-bb5cf11e81b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
