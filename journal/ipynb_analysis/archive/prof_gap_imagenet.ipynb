{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc7d8b-bf04-4ec5-84fa-8df1ce6b03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b1604-6efe-4815-9896-3b9313e4f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    #f'cuda:{torch.cuda.device_count() - 1}' if torch.cuda.is_available() else 'cpu'\n",
    "    'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "capability = torch.cuda.get_device_capability() if device.type == 'cuda' else None\n",
    "torch.jit.enable_onednn_fusion(True)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_device(device)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "mem_info = torch.cuda.mem_get_info(device=device) # global (free, total) GPU memor\n",
    "print(f'Device: {device}, Type: {device.type}, Compute_Capability: {capability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66b38f-450d-4253-a71d-6e28f060369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    GPU_info = {\n",
    "        'device_name': torch.cuda.get_device_name(device=device),\n",
    "        'mem_info': torch.cuda.mem_get_info(device=device),\n",
    "    }\n",
    "    print(f'GPU Name: {GPU_info['device_name']}, Memory (free, total): {GPU_info['mem_info']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897f073-3927-4491-9069-72c2de3af2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/.pytorch/dataset'\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transform_pre = nn.Sequential(\n",
    "    transforms.ToDtype(torch.uint8, scale=True),\n",
    "    )\n",
    "transform_post = nn.Sequential(\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(dtype=torch.float32, scale=True),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    ")\n",
    "transform = {\n",
    "    'train': nn.Sequential(\n",
    "        transform_pre,\n",
    "        transforms.RandomResizedCrop(size=224, scale=(.8, 1), ratio=(.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transform_post,\n",
    "    ),\n",
    "    'eval': nn.Sequential(\n",
    "        transform_pre,\n",
    "        #transforms.Resize(size=256),\n",
    "        #transforms.CenterCrop(size=size),\n",
    "        transform_post,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468eb9b-61b4-4a08-8c18-46baca1ae705",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/ssd/imagenet/'\n",
    "dataset = {\n",
    "    'train': datasets.ImageFolder(root=root+'train/', transform=transform['train']),\n",
    "    'eval': datasets.ImageFolder(root=root+'val/', transform=transform['eval']),\n",
    "}\n",
    "model = models.resnet18().to(device, memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a790a-2904-42a9-9faa-192973c46003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(model, dataset, dataloader, criterion, optimizer):\n",
    "    # record\n",
    "    record_loss, record_acc = 0, 0\n",
    "    # train\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # load data\n",
    "        inputs = data[0].to(device, non_blocking=True, memory_format=torch.channels_last)\n",
    "        labels = data[1].to(device, non_blocking=True)\n",
    "        # compute\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        with torch.autocast(device.type, enabled=AUTOCAST_FLAG):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record\n",
    "        #record_loss += loss.item()\n",
    "        #record_acc += (labels.argmax(dim=1) == outputs.argmax(dim=1)).sum().item()\n",
    "        break\n",
    "    # results\n",
    "    #record_loss /= len(dataloader) # mean loss\n",
    "    #record_acc /= (len(dataset) - (len(dataset) % batch_size)) if AUTOCAST_FLAG else len(dataset)\n",
    "    return record_loss, record_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ce8af-4b62-4a46-9e6c-a607cb8ebb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed_mem(fn):\n",
    "    torch.cuda.reset_peak_memory_stats(device=device)\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000, torch.cuda.max_memory_allocated(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a12d9d-3406-430a-8381-678a3f559b98",
   "metadata": {},
   "source": [
    "## BS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd74385-e9b7-4e0d-acbd-9834ed649338",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=num_workers,\n",
    "        #collate_fn=collate_fn if MIX_FLAG else None,\n",
    "        #pin_memory=True,\n",
    "        #drop_last=AUTOCAST_FLAG,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=num_workers,\n",
    "        #pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498abfc5-150d-4f90-99f6-1f361ad8633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaed2d5-12ab-415c-8475-a9eef7b5e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_1 = mem_cost\n",
    "print(mem_bs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e26f2d-0d1a-4032-8e8f-ba0796d51c51",
   "metadata": {},
   "source": [
    "## BS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a7d22-19d1-4362-b4f6-d64d73bd7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=num_workers,\n",
    "        #collate_fn=collate_fn if MIX_FLAG else None,\n",
    "        #pin_memory=True,\n",
    "        #drop_last=AUTOCAST_FLAG,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=num_workers,\n",
    "        #pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e8193-86e4-472b-a8a3-9e11e7991f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84002d64-480a-4f02-800e-448784756ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_2 = mem_cost\n",
    "print(mem_bs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178743e0-6e6f-4673-a9d5-8c6f37835b05",
   "metadata": {},
   "source": [
    "## Predict ${BS}_{MAX}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323929c0-2910-49c6-a61e-6d1a3d989195",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_cost_gap = mem_bs_2 - mem_bs_1\n",
    "print(mem_cost_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae8049-8688-46af-bda4-858e98a8a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_max = (GPU_info['mem_info'][0] - mem_bs_1) // mem_cost_gap + 1\n",
    "print(batch_size_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad8106-d4b0-4d1f-ad7c-fc8179b4b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_max_predict = mem_bs_1 + (batch_size_max - 1) * mem_cost_gap\n",
    "print(mem_bs_max_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6645ab-a313-4ea9-af42-0c65c62b26c5",
   "metadata": {},
   "source": [
    "## BS = MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11033f-01a0-4308-98ec-0ddb6775c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = batch_size_max\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=num_workers,\n",
    "        #collate_fn=collate_fn if MIX_FLAG else None,\n",
    "        #pin_memory=True,\n",
    "        #drop_last=AUTOCAST_FLAG,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=num_workers,\n",
    "        #pin_memory=True,\n",
    "        drop_last=False,\n",
    "        #persistent_workers=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3ebce-e35b-42e5-8371-c0262fce3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510947f-3128-4f89-ab24-1f4298326d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_size_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365cb44-2ecc-4912-99aa-bd8eb57df0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_bs_max_measure = mem_cost\n",
    "print(mem_bs_max_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3fcc3-e37c-454a-9eed-c868fefae731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GAP: {(GPU_info['mem_info'][0] - mem_bs_max_measure) / 2**20} MiB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fcc937-142e-4fe3-b651-8b842ae51d40",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160c281-d159-4b3f-a6f4-cfa1a3443e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GPU Name: {GPU_info['device_name']}, Memory (free, total): {GPU_info['mem_info']}')\n",
    "print(f'Predict batch size: {batch_size_max}')\n",
    "print(f'Predict memory usage: {mem_bs_max_predict} Byte == {mem_bs_max_predict // 2**20: g} MiB')\n",
    "print(f'Measure memory usage: {mem_bs_max_measure} Byte == {mem_bs_max_measure // 2**20: g} MiB')\n",
    "print(f'Gap of memory usage: {mem_bs_max_predict - mem_bs_max_measure} Byte == {(mem_bs_max_predict - mem_bs_max_measure) // 2**20: g} MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5954253-1a03-47e7-afcb-39b5aa4de62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
