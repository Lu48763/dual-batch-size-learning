{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6526d-6c8b-4914-8c30-1fe2c4151a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import typing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models\n",
    "\n",
    "import cifar_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45e99f-2345-48ac-88b8-aff58dbbd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    #f'cuda:{torch.cuda.device_count() - 1}' if torch.cuda.is_available() else 'cpu'\n",
    "    'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "capability = torch.cuda.get_device_capability() if device.type == 'cuda' else None\n",
    "torch.jit.enable_onednn_fusion(True)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_device(device)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "mem_info = torch.cuda.mem_get_info(device=device) # global (free, total) GPU memor\n",
    "print(f'Device: {device}, Type: {device.type}, Compute_Capability: {capability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcae607-1fe4-4171-b1bc-2c76895e1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    GPU_info = {\n",
    "        'device_name': torch.cuda.get_device_name(device=device),\n",
    "        'mem_info': torch.cuda.mem_get_info(device=device),\n",
    "    }\n",
    "    print(f'GPU Name: {GPU_info['device_name']}, Memory (free, total): {GPU_info['mem_info']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4079a-ebf9-4d1e-a35a-f894971ea326",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/.pytorch/dataset'\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transform_pre = nn.Sequential(\n",
    "    transforms.ToDtype(torch.uint8, scale=True),\n",
    "    )\n",
    "transform_post = nn.Sequential(\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(dtype=torch.float32, scale=True),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    ")\n",
    "transform = {\n",
    "    'train': nn.Sequential(\n",
    "        transform_pre,\n",
    "        transforms.RandomResizedCrop(size=32, scale=(.8, 1), ratio=(.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transform_post,\n",
    "    ),\n",
    "    'eval': nn.Sequential(\n",
    "        transform_pre,\n",
    "        transform_post,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148469c2-a46a-49b2-bc5f-a2f2446da852",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '~/.pytorch/datasets'\n",
    "dataset = {\n",
    "    'train': datasets.CIFAR100(root=root, train=True, transform=transform['train'], download=True),\n",
    "    'eval': datasets.CIFAR100(root=root, train=False, transform=transform['eval'], download=True),\n",
    "}\n",
    "model = cifar_resnet.CIFAR_ResNet(n=3, num_classes=100, p=0.2).to(device, memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383db01-6cd4-4bb3-a7c8-eb20f7172f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(model, dataset, dataloader, criterion, optimizer):\n",
    "    # record\n",
    "    record_loss, record_acc = 0, 0\n",
    "    # train\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # load data\n",
    "        inputs = data[0].to(device, non_blocking=True, memory_format=torch.channels_last)\n",
    "        labels = data[1].to(device, non_blocking=True)\n",
    "        # compute\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        with torch.autocast(device.type, enabled=AUTOCAST_FLAG):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record\n",
    "        #record_loss += loss.item()\n",
    "        #record_acc += (labels.argmax(dim=1) == outputs.argmax(dim=1)).sum().item()\n",
    "        break\n",
    "    # results\n",
    "    #record_loss /= len(dataloader) # mean loss\n",
    "    #record_acc /= (len(dataset) - (len(dataset) % batch_size)) if AUTOCAST_FLAG else len(dataset)\n",
    "    return record_loss, record_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06dd73d-d922-499c-bb8a-78bb35365daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed_mem(fn):\n",
    "    torch.cuda.reset_peak_memory_stats(device=device)\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000, torch.cuda.max_memory_allocated(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d90f8-ed58-4efe-9392-41b3b206a182",
   "metadata": {},
   "source": [
    "### Get Mem Usage, BS = [128, 256, 384, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792493a-dac9-426c-ad60-fd4c506826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_ls = list(range(64, 512+1, 64))\n",
    "mem_cost_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5dc76c-1030-4e60-af1a-fbd580832bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size in batch_size_ls:\n",
    "\n",
    "    ## configuration\n",
    "    dataloader = {\n",
    "        'train': torch.utils.data.DataLoader(\n",
    "            dataset['train'],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        ),\n",
    "        'eval': torch.utils.data.DataLoader(\n",
    "            dataset['eval'],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "    #optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)\n",
    "\n",
    "    ## training\n",
    "    result, time_cost, mem_cost = timed_mem(\n",
    "        lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    "    )\n",
    "\n",
    "    ## result\n",
    "    mem_cost_ls.append(mem_cost)\n",
    "    print(batch_size, mem_cost_ls[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4e44b-c067-4d6c-a5f6-a967a033e5b0",
   "metadata": {},
   "source": [
    "### Predict Mem, Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80845a14-c0af-4108-80f3-6452384ce508",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = LinearRegression().fit(np.array(batch_size_ls).reshape(-1, 1), np.array(mem_cost_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a9a74-3dea-4978-880f-206c4a1af1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_model.intercept_, reg_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47fcd6-257d-4a4a-9e55-fbf5603ae833",
   "metadata": {},
   "source": [
    "### Get Predict Max Mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a78cb-2a0a-4ad0-b986-202c8f0b4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_max = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0a2d0-6450-4542-b4a1-6a534b8ecb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bs_ls = np.arange(1, guess_max + 1)\n",
    "predict_mem_ls = reg_model.predict(predict_bs_ls.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce150d5-57a6-4ad9-8ec7-bd9a05afb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bs = predict_mem_ls[predict_mem_ls <= GPU_info['mem_info'][0]].argmax() + 1\n",
    "predict_mem = predict_mem_ls[predict_mem_ls <= GPU_info['mem_info'][0]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf2848-d01b-4032-b57e-dbb3a309688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GPU mem: {GPU_info['mem_info'][0]}')\n",
    "print(f'predict max bs: {predict_bs}')\n",
    "print(f'predict max mem: {predict_mem}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14bc5b-b63c-49cd-ba05-9fdba76d8347",
   "metadata": {},
   "source": [
    "### Get Measure Max Mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0579152-7778-4c33-917f-4312f29d91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(predict_bs)\n",
    "\n",
    "## configuration\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    'eval': torch.utils.data.DataLoader(\n",
    "        dataset['eval'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    ),\n",
    "}\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1 * (batch_size / 128), momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=1e-3 * (batch_size / 1024), weight_decay=0.05)\n",
    "\n",
    "## training\n",
    "result, time_cost, mem_cost = timed_mem(\n",
    "    lambda: train_a_batch(model, dataset['train'], dataloader['train'], criterion, optimizer)\n",
    ")\n",
    "\n",
    "## result\n",
    "print(batch_size, mem_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389412cf-d556-40b7-a36e-ab59889355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_mem = mem_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1362-8474-4552-b882-247744047781",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd59499-e1f1-4376-9e79-367461a69692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GPU Name: {GPU_info['device_name']}, Memory (free, total): {GPU_info['mem_info']}')\n",
    "print(f'Predict batch size: {predict_bs}')\n",
    "print(f'Predict memory usage: {predict_mem} Byte == {predict_mem // 2**20: g} MiB')\n",
    "print(f'Measure memory usage: {measure_mem} Byte == {measure_mem // 2**20: g} MiB')\n",
    "print(f'Gap of memory usage: {predict_mem - measure_mem} Byte == {(predict_mem - measure_mem) // 2**20: g} MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8b68d-dc4d-4ff0-8b0a-f5fdb4811783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e150cfb-10a8-4f93-b27d-e5711a5a1630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
